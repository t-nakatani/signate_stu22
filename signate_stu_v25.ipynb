{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "signate_stu_v25.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMiEOUj7GcrwH2b1AadGuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "600658849e824c2899f9c371dec96e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16ed669745ce43f495d3491ba67a383a",
              "IPY_MODEL_8a1f97b174e643708dfd3ef56f8334b8",
              "IPY_MODEL_5cdb39af90e041178e98bedca94846ed"
            ],
            "layout": "IPY_MODEL_2a970269b1f8442da3d783a548b9a00c"
          }
        },
        "16ed669745ce43f495d3491ba67a383a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6bff4d8f70e46b89074333ca28a98cd",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5a568cf6954a84abf09af2ef4a5d31",
            "value": "Downloading: 100%"
          }
        },
        "8a1f97b174e643708dfd3ef56f8334b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be3b192f5124d299a646411a0901470",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77ffc7e8d0724ac1849db2bbc74ddcdb",
            "value": 440473133
          }
        },
        "5cdb39af90e041178e98bedca94846ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a172b6e94c4bcf9704f845ff39b561",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd0bfd2a3ee4f909c0815766060acd6",
            "value": " 440M/440M [00:12&lt;00:00, 24.9MB/s]"
          }
        },
        "2a970269b1f8442da3d783a548b9a00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6bff4d8f70e46b89074333ca28a98cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5a568cf6954a84abf09af2ef4a5d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be3b192f5124d299a646411a0901470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ffc7e8d0724ac1849db2bbc74ddcdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99a172b6e94c4bcf9704f845ff39b561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd0bfd2a3ee4f909c0815766060acd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-nakatani/signate_stu22/blob/exp/signate_stu_v25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v20との比較でv10を再現\n",
        "\n",
        "*   max_len = 400\n",
        "*   5-fold\n",
        "\n"
      ],
      "metadata": {
        "id": "GDti4y2d6yb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ofvp5QVbEagJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2d9e22-aa85-4e1d-b22d-6dbb342433cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT = \"/content/drive/MyDrive/Colab Notebooks/signate/\"\n",
        "\n",
        "#学習用データと評価用データの読み込み\n",
        "train = pd.read_csv(os.path.join(ROOT, \"train.csv\")).drop_duplicates(subset='description')\n",
        "test = pd.read_csv(os.path.join(ROOT, \"test.csv\"))\n",
        "\n",
        "jobdic = dict(zip([1, 2, 3, 4], ['DataScientist', 'ML Engineer', 'Software Engineer', 'Consultant']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def cleaning(texts):\n",
        "    clean_texts = []\n",
        "    for text in texts:\n",
        "        # htmlタグを削除\n",
        "        text = remove_tag(text)\n",
        "        # #アルファベット以外をスペースに置き換え\n",
        "        clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "        #単語長が1文字以下のものは削除する\n",
        "        clean_short_tokenized = [word for word in clean_punc.split() if len(word) > 1]\n",
        "        #単語同士をスペースでつなぎ, 文章に戻す\n",
        "        clean_text = ' '.join(clean_short_tokenized)\n",
        "        \n",
        "        clean_texts.append(clean_text)\n",
        "    return clean_texts\n",
        "\n",
        "def remove_tag(x):\n",
        "    p = re.compile(r\"<[^>]*?>\")\n",
        "    return p.sub('',x)\n",
        "\n",
        "train['description'] = cleaning(train['description'])\n",
        "test['description'] = cleaning(test['description'])"
      ],
      "metadata": {
        "id": "Zg7O_R-U1tuS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EfzhwNtb2sG6",
        "outputId": "f169e851-3dde-43d8-9eec-56d0c095b03d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                        description  jobflag\n",
              "0        0  Develop cutting edge web applications that per...        3\n",
              "1        1  Designs and develops high quality scalable and...        3\n",
              "2        2  Functions as point person for Network Strategy...        4\n",
              "3        3  Work on the technical design development relea...        3\n",
              "4        4  Quantify the resources required for task proje...        4\n",
              "...    ...                                                ...      ...\n",
              "1511  1511  Support detailed reporting statistical analyse...        1\n",
              "1512  1512  Collaborate with teams to support the ML techn...        2\n",
              "1513  1513  Work with executives and other business leader...        1\n",
              "1514  1514  Leading design ideation sessions to ensure we ...        3\n",
              "1515  1515  Detection of Issues amp Impact Assessments eg ...        1\n",
              "\n",
              "[1507 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39abab6f-6663-4868-86d3-add86ce0583b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>jobflag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Develop cutting edge web applications that per...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Designs and develops high quality scalable and...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Functions as point person for Network Strategy...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Work on the technical design development relea...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Quantify the resources required for task proje...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>1511</td>\n",
              "      <td>Support detailed reporting statistical analyse...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>1512</td>\n",
              "      <td>Collaborate with teams to support the ML techn...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>1513</td>\n",
              "      <td>Work with executives and other business leader...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>1514</td>\n",
              "      <td>Leading design ideation sessions to ensure we ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1515</td>\n",
              "      <td>Detection of Issues amp Impact Assessments eg ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1507 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39abab6f-6663-4868-86d3-add86ce0583b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39abab6f-6663-4868-86d3-add86ce0583b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39abab6f-6663-4868-86d3-add86ce0583b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==3"
      ],
      "metadata": {
        "id": "YisF3KcxVqbT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from transformers import RobertaTokenizer, RobertaModel\n",
        "# from transformers import BertModel, AutoTokenizer \n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "from torch import optim\n",
        "from torch import cuda\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "IrNv3cPZOec-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seeds\n",
        "SEED = 2022\n",
        "def seed_everything(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    current_device = torch.cuda.current_device()\n",
        "    print(\"Device:\", torch.cuda.get_device_name(current_device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnz-PWYD9S92",
        "outputId": "dbfe11f8-2c2f-4324-acda-b95e9353ae1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasetの定義\n",
        "class CreateDataset(Dataset):\n",
        "  def __init__(self, X, y, tokenizer, max_len):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):  # len(Dataset)で返す値を指定\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
        "    text = self.X[index]\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True\n",
        "    )\n",
        "    ids = inputs['input_ids']\n",
        "    mask = inputs['attention_mask']\n",
        "    labels = self.y[index]\n",
        "\n",
        "    return {\n",
        "      'ids': torch.LongTensor(ids),\n",
        "      'mask': torch.LongTensor(mask),\n",
        "      'labels': torch.Tensor(labels)\n",
        "    }"
      ],
      "metadata": {
        "id": "bTbjxDE60aFs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. from_pretrainedの文字列でconfig.from_pretrainedを呼び出し\n",
        "2. config.from_pretrainedの結果をconfigにセット"
      ],
      "metadata": {
        "id": "yYsvP_-hf-pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT分類モデルの定義\n",
        "class BERTClass(torch.nn.Module):\n",
        "  def __init__(self, drop_rate, otuput_size):\n",
        "    super().__init__()\n",
        "    self.config = AutoConfig.from_pretrained('bert-base-uncased', num_labels=4)\n",
        "    self.bert = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', config=self.config)\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    out = self.bert(ids, attention_mask=mask)\n",
        "    return out[0]"
      ],
      "metadata": {
        "id": "M38JBNnv7QA4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_and_f1_score(model, criterion, loader, device, epoch, max_epoch):\n",
        "  \"\"\" 損失・正解率を計算\"\"\"\n",
        "  model.eval()\n",
        "  loss = 0.0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  all_labels = []\n",
        "  all_preds = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    with tqdm(loader) as pbar:\n",
        "      pbar.set_description('valid')\n",
        "      for i, data in enumerate(pbar):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        labels = data['labels'].to(device)\n",
        "\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss += criterion(outputs, labels).item()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=-1).cpu().numpy() # バッチサイズの長さの予測ラベル配列\n",
        "        labels = torch.argmax(labels, dim=-1).cpu().numpy()  # バッチサイズの長さの正解ラベル配列\n",
        "        all_labels += labels.tolist()\n",
        "        all_preds += preds.tolist()\n",
        "        total += len(labels)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        pbar.set_postfix(loss=loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
        "\n",
        "  return loss / len(loader), f1_score(all_labels, all_preds, average=\"macro\")"
      ],
      "metadata": {
        "id": "KFQSOOn7SbPp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(train_loader, val_loader, model_path):\n",
        "  device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "  model = BERTClass(DROP_RATE, OUTPUT_SIZE).to(device)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
        "  \n",
        "  log_valid = []\n",
        "  best_acc = 0\n",
        "  all_labels = []\n",
        "  all_preds = []\n",
        "\n",
        "  # train\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print('\\nepoch:', epoch+1)\n",
        "    loss_train = correct = total = 0\n",
        "    model.train()\n",
        "    with tqdm(train_loader) as pbar:\n",
        "      pbar.set_description('train')\n",
        "      for i, data in enumerate(pbar):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        labels = data['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_train += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "        labels = torch.argmax(labels, dim=-1).cpu().numpy()\n",
        "\n",
        "        all_labels += labels.tolist()\n",
        "        all_preds += preds.tolist()\n",
        "\n",
        "        total += len(labels)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        pbar.set_postfix(loss=loss_train/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
        "\n",
        "    loss_valid, f1_valid = calculate_loss_and_f1_score(model, criterion, val_loader, device, epoch, NUM_EPOCHS)\n",
        "    log_valid.append([loss_valid, f1_valid])\n",
        "    if best_acc < f1_valid:\n",
        "      best_acc = f1_valid\n",
        "      \n",
        "      torch.save(model, os.path.join(ROOT, model_path))\n",
        "      print('==== model saved ====')\n",
        "\n",
        "  return log_valid"
      ],
      "metadata": {
        "id": "T9Hy83GPWD1C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DROP_RATE = 0.1\n",
        "OUTPUT_SIZE = 4\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "N_CV = 5\n",
        "VERSION = 'v25'"
      ],
      "metadata": {
        "id": "XfF5KLQJWJCG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "def train_val_predict(\n",
        "        df_train,       # 学習用のデータ\n",
        "        text_column,    # 対象のカラム名\n",
        "        target_column,  # 目的変数のカラム名\n",
        "        df_valid=None,  # 検証用データ\n",
        "        df_val_test=None,       # 予測用データ\n",
        "        model_file_prefix=\"\",  # 保存時のファイル名識別子\n",
        "        epochs=NUM_EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    ):\n",
        "  \n",
        "    # model\n",
        "    model_path = \"{}_{}.pth\".format(model_file_prefix, VERSION)\n",
        "    model = BERTClass(DROP_RATE, OUTPUT_SIZE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "    # dataset\n",
        "    df_val_test[target_column].fillna(0)\n",
        "\n",
        "    max_len = 400\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    dataset_train = CreateDataset(df_train[text_column].values, pd.get_dummies(df_train[target_column]).values, tokenizer, max_len)\n",
        "    dataset_val = CreateDataset(df_valid[text_column].values, pd.get_dummies(df_valid[target_column]).values, tokenizer, max_len)\n",
        "    dataset_test = CreateDataset(df_val_test[text_column].values, pd.get_dummies(df_val_test[target_column]).values, tokenizer, max_len)\n",
        "\n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    dataloader_valid = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    print('\\n================  start train  ================')\n",
        "    metric = train_val(dataloader_train, dataloader_valid, model_path)\n",
        "    print('================  end train  ================\\n')\n",
        "\n",
        "    # predict\n",
        "    model = torch.load(os.path.join(ROOT, model_path))\n",
        "    model.eval()\n",
        "    pred_y_list = []\n",
        "    emb_list = []\n",
        "    with torch.no_grad():\n",
        "      with tqdm(dataloader_test) as pbar:\n",
        "        pbar.set_description('test')\n",
        "        for data in pbar:\n",
        "          ids = data['ids'].to(device)\n",
        "          mask = data['mask'].to(device)\n",
        "          labels = data['labels'].to(device)\n",
        "\n",
        "          output = model.forward(ids, mask)\n",
        "          pred = torch.argmax(output, dim=-1).cpu().numpy()\n",
        "\n",
        "          pred_y_list.extend(pred)\n",
        "          emb_list.extend(output.cpu().numpy())\n",
        "    return metric, pred_y_list, emb_list"
      ],
      "metadata": {
        "id": "La2mPphur18q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "\n",
        "text_column, target_column, n_splits = ('description', 'jobflag', N_CV)\n",
        "\n",
        "df = pd.concat([train, test], ignore_index=True, sort=False)\n",
        "df_train = df[df[target_column].notnull()]\n",
        "df_test = df[df[target_column].isnull()]\n",
        "\n",
        "df_train_idx = df_train.index\n",
        "\n",
        "# store result\n",
        "df_pred = pd.DataFrame(df.index, columns=[\"index\"]).set_index(\"index\")\n",
        "df_emb = pd.DataFrame(df.index, columns=[\"index\"]).set_index(\"index\")\n",
        "df_emb_pred = None\n",
        "metric_list = []\n",
        "all_emb = []\n",
        "\n",
        "# cross validation\n",
        "kf = sklearn.model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "for i, (train_idx, test_idx) in enumerate(kf.split(df_train, df_train[target_column])):\n",
        "  df_train_sub = df_train.iloc[train_idx]\n",
        "  df_test_sub = df_train.iloc[test_idx]\n",
        "\n",
        "  df_val_test = pd.concat([df_test_sub, df_test], ignore_index=True, sort=False)\n",
        "\n",
        "  model_file_prefix = \"cv_{}\".format(i)\n",
        "\n",
        "  # train\n",
        "  metric, pred_y_list, emb_list = train_val_predict(\n",
        "      df_train=df_train_sub, \n",
        "      text_column=text_column,\n",
        "      target_column=target_column, \n",
        "      df_valid=df_test_sub,\n",
        "      df_val_test=df_val_test,\n",
        "      model_file_prefix=model_file_prefix,\n",
        "  )\n",
        "  metric_list.append(metric)\n",
        "  all_emb.append(emb_list)\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "600658849e824c2899f9c371dec96e42",
            "16ed669745ce43f495d3491ba67a383a",
            "8a1f97b174e643708dfd3ef56f8334b8",
            "5cdb39af90e041178e98bedca94846ed",
            "2a970269b1f8442da3d783a548b9a00c",
            "f6bff4d8f70e46b89074333ca28a98cd",
            "6e5a568cf6954a84abf09af2ef4a5d31",
            "1be3b192f5124d299a646411a0901470",
            "77ffc7e8d0724ac1849db2bbc74ddcdb",
            "99a172b6e94c4bcf9704f845ff39b561",
            "8bd0bfd2a3ee4f909c0815766060acd6"
          ]
        },
        "id": "QB2vixNEo7_B",
        "outputId": "bdd3a852-7623-45ee-f3f0-b746eee65412"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "600658849e824c2899f9c371dec96e42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================  start train  ================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.463, loss=1.01]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.549, loss=0.769]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.527, loss=0.685]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.568, loss=0.794]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.595, loss=0.504]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.68, loss=0.732]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.651, loss=0.334]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.676, loss=0.837]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.712, loss=0.18]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.618, loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.758, loss=0.0955]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.663, loss=0.934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.786, loss=0.137]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.633, loss=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.81, loss=0.108]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.628, loss=0.999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.829, loss=0.0709]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.701, loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.846, loss=0.028]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.628, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================  end train  ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 114/114 [00:26<00:00,  4.23it/s]\n",
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================  start train  ================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.51it/s, f1=0.419, loss=1.08]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.557, loss=0.815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.508, loss=0.683]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.59, loss=0.674]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.602, loss=0.492]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.678, loss=0.691]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.67, loss=0.323]\n",
            "valid: 100%|██████████| 19/19 [00:06<00:00,  3.07it/s, f1=0.705, loss=0.808]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:53<00:00,  1.41it/s, f1=0.721, loss=0.219]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.701, loss=0.773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.762, loss=0.157]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.632, loss=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.792, loss=0.0986]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.695, loss=0.934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.818, loss=0.0529]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.16it/s, f1=0.674, loss=0.994]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.838, loss=0.0465]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.665, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.853, loss=0.0513]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.62, loss=1.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================  end train  ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 114/114 [00:26<00:00,  4.27it/s]\n",
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================  start train  ================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.435, loss=1.03]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.553, loss=0.742]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.537, loss=0.659]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.641, loss=0.729]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.612, loss=0.489]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.22it/s, f1=0.652, loss=0.725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.683, loss=0.325]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.08it/s, f1=0.658, loss=0.726]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.724, loss=0.254]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.22it/s, f1=0.693, loss=0.807]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.758, loss=0.175]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.19it/s, f1=0.634, loss=0.906]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.789, loss=0.0965]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.647, loss=0.944]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.814, loss=0.0665]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.20it/s, f1=0.703, loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.47it/s, f1=0.835, loss=0.0406]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.20it/s, f1=0.683, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.852, loss=0.0314]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.20it/s, f1=0.693, loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================  end train  ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 114/114 [00:26<00:00,  4.22it/s]\n",
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================  start train  ================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.51it/s, f1=0.427, loss=1.08]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.20it/s, f1=0.54, loss=0.819]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.493, loss=0.74]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.22it/s, f1=0.624, loss=0.768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.562, loss=0.524]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.22it/s, f1=0.682, loss=0.702]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.634, loss=0.361]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.20it/s, f1=0.678, loss=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.694, loss=0.235]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.623, loss=0.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.74, loss=0.142]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.608, loss=0.838]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.773, loss=0.104]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.22it/s, f1=0.675, loss=0.866]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.801, loss=0.0638]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.671, loss=0.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.824, loss=0.038]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.706, loss=0.996]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.47it/s, f1=0.842, loss=0.0171]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.21it/s, f1=0.683, loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================  end train  ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 114/114 [00:26<00:00,  4.27it/s]\n",
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================  start train  ================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.51it/s, f1=0.462, loss=1.01]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.573, loss=0.739]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.525, loss=0.657]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.658, loss=0.651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.50it/s, f1=0.597, loss=0.449]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.16it/s, f1=0.645, loss=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.67, loss=0.303]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.683, loss=0.752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:50<00:00,  1.49it/s, f1=0.721, loss=0.229]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.713, loss=0.754]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== model saved ====\n",
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.763, loss=0.125]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.686, loss=0.818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.798, loss=0.0718]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.16it/s, f1=0.675, loss=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.825, loss=0.0365]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.17it/s, f1=0.68, loss=0.982]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.49it/s, f1=0.847, loss=0.0264]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.18it/s, f1=0.686, loss=0.988]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 76/76 [00:51<00:00,  1.48it/s, f1=0.863, loss=0.0165]\n",
            "valid: 100%|██████████| 19/19 [00:04<00:00,  4.16it/s, f1=0.663, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================  end train  ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 114/114 [00:26<00:00,  4.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_emb_ = np.array([np.array(emb)[-len(df_test):] for emb in all_emb])"
      ],
      "metadata": {
        "id": "eK-UI_G3wzIG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_df = pd.DataFrame([[np.mean(arr_val) for arr_val in arr_vec] for arr_vec in np.moveaxis(all_emb_, 0, 2)])\n",
        "preds = [np.argmax(arr)+1 for arr in mean_df.to_numpy()]\n",
        "df_submit = pd.DataFrame([df_test.id.to_list(), preds]).T\n",
        "df_submit.to_csv(os.path.join(ROOT, f'{VERSION}_ensemble.csv'), index=None, header=None)"
      ],
      "metadata": {
        "id": "zHARK-Z-lvL8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_list = []\n",
        "for item in metric_list:\n",
        "  f1_list.append((np.max([acc for loss, acc in item])))\n",
        "print(np.mean(f1_list))"
      ],
      "metadata": {
        "id": "JVEj-oYop9as",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6459832c-ca1c-43d8-d2e5-3e622bab7283"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7058908280971141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "for item in metric_list:\n",
        "  loss_list.append((np.min([loss for loss, acc in item])))\n",
        "print(np.mean(loss_list))"
      ],
      "metadata": {
        "id": "chcdmZd0W5_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0248b418-7c6b-45df-b292-067245dd777e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6968038657778188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q_gfSqrqQ-Cc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}